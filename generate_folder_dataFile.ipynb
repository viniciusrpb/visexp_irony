{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that receives a TF-IDF structure and writes to a .DATA or .CSV file\n",
    "\n",
    "Parameters:\n",
    "path - path to .data (or .csv) file\n",
    "vectorizer - \n",
    "tfidf - matrix\n",
    "categories - a vector with N indices describing the categories of each text instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDataFile(path,vectorizer,tfidf,categories):\n",
    "    \n",
    "    data_file = open(path, \"w\")\n",
    "    \n",
    "    [nroInstances,nroAtributtes] = tfidf.shape\n",
    "    \n",
    "    print(\"Number of instaces\")\n",
    "    print(tfidf.shape)\n",
    "    \n",
    "    line = \"DY\\n\"+str(nroInstances)+\"\\n\"+str(nroAtributtes-1)+\"\\n\"\n",
    "    \n",
    "    n = data_file.write(line)\n",
    "    \n",
    "    atts = vectorizer.get_feature_names()\n",
    "\n",
    "    line=atts[0]\n",
    "    for i in range(1,len(atts)-1):\n",
    "        line = line+\";\"+str(atts[i-1])\n",
    "        \n",
    "    line = line+\"\\n\"\n",
    "\n",
    "    n = data_file.write(line)\n",
    "    \n",
    "    for i in range(0,nroInstances):\n",
    "        line = 'tweet'+str(i+1)+'.txt;';\n",
    "        for j in range(0,nroAtributtes-1):\n",
    "            line = line+str(round(tfidf[i,j], 5))+\";\"\n",
    "        line = line+str(categories[i])+\"\\n\"\n",
    "\n",
    "        n = data_file.write(line)\n",
    "            \n",
    "    data_file.close()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions that converts \"string\" labels to \"integer\" labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLabels_String2Int(classes):\n",
    "\n",
    "    classesInt = []\n",
    "    for i in range(1,len(classes)+1):\n",
    "        classesInt.append(0)\n",
    "\n",
    "\n",
    "    classesUnique = np.unique(classes)\n",
    "    for i in range(1,len(classes)):\n",
    "        for j in range(1,len(classesUnique)):\n",
    "            if classes[i] == classesUnique[j]:\n",
    "                classesInt[i] = j;\n",
    "                \n",
    "    return classesInt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that generates a folder of the original tweets in single files and a list with all tweets and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFolder(file_tweets,path_folder):\n",
    "    \n",
    "    tweets = []\n",
    "    classes = []\n",
    "    num = 0;\n",
    "    \n",
    "    try: \n",
    "        os.mkdir(path_folder)\n",
    "        print(\"Directory '%s' created\" %directory) \n",
    "    except OSError as error: \n",
    "        print(error)  \n",
    "\n",
    "    while True:\n",
    "\n",
    "        line = file_tweets.readline()\n",
    "\n",
    "        if line:\n",
    "            tweetsJustRead = line.split(\"\\t\",2)\n",
    "            tweetpos = [tweetsJustRead[2]]\n",
    "            category = [tweetsJustRead[1]]\n",
    "\n",
    "            tweet = tweetpos[0]\n",
    "            #print(tweet+\" \"+category[0])\n",
    "            strnum = str(num)\n",
    "            path_filedata = path_folder+'/tweet'+str(strnum)+'.txt';\n",
    "\n",
    "            text_file = open(path_filedata, \"w\")\n",
    "            n = text_file.write(tweet)\n",
    "            text_file.close()\n",
    "\n",
    "            tweets.append(tweet)\n",
    "            classes.append(category[0])\n",
    "\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        num=num+1\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    return tweets,classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_set = 'data/SemEval2018-T3-train-taskA.txt'\n",
    "path_zip = 'tweets'\n",
    "dataFile_name = 'tweets_irony_train_2018.data'\n",
    "\n",
    "file_tweets = open(path_set,'r',encoding =\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'tweets'\n"
     ]
    }
   ],
   "source": [
    "tweets,categories = generateZip(file_tweets,path_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert \"string\" labels to \"integer\" labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoriesInt = convertLabels_String2Int(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute TF-IDF representation from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(norm=None, stop_words=\"english\",max_df=0.95, min_df=2)\n",
    "tfidf = vectorizer.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create .data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3835, 3427)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-bffcc31c10f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriteDataFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategoriesInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-cb4cd262523a>\u001b[0m in \u001b[0;36mwriteDataFile\u001b[0;34m(path, vectorizer, tfidf, categories)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tweet'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt;'\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnroAtributtes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_get_intXint\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    644\u001b[0m         indptr, indices, data = get_csr_submatrix(\n\u001b[1;32m    645\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             major, major + 1, minor, minor + 1)\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writeDataFile(dataFile_name,vectorizer,tfidf,categoriesInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
